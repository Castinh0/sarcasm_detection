{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "686056c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 1/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 2/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 3/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 4/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 5/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 6/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 7/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 8/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 9/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 10/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 11/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 12/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 13/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 14/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "Iteration: 15/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 16/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 17/18\n",
      "\u001b[1m97/97\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
      "Iteration: 18/18\n"
     ]
    }
   ],
   "source": [
    "from model_selection import train\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "remove_stop_words_values = [False]\n",
    "remove_punctuations_values = [False]\n",
    "to_lower_values = [False]\n",
    "vocab_size_values = [10000,20000,30000]\n",
    "embedding_dim_values = [32,64,128]\n",
    "sentence_length_threshold_values = [-1]\n",
    "learning_rate_values = [0.00005, 0.0001]\n",
    "\n",
    "\n",
    "param_list = []\n",
    "res_list = []\n",
    "\n",
    "iteration = 1\n",
    "\n",
    "total_iteration_length = len(remove_stop_words_values) * len(remove_punctuations_values) * len(to_lower_values) * len(vocab_size_values) * len(embedding_dim_values) * len(sentence_length_threshold_values) * len(learning_rate_values)\n",
    "\n",
    "for remove_stop_words in remove_stop_words_values:\n",
    "    for remove_punctuations in remove_punctuations_values:\n",
    "        for to_lower in to_lower_values:\n",
    "            for vocab_size in vocab_size_values:\n",
    "                for embedding_dim in embedding_dim_values:\n",
    "                    for sentence_length_threshold in sentence_length_threshold_values:\n",
    "                        for learning_rate in learning_rate_values:\n",
    "                            \n",
    "                            params, results = train(remove_stop_words, remove_punctuations, to_lower, vocab_size, embedding_dim, sentence_length_threshold, learning_rate)\n",
    " \n",
    "                            params.insert(0, iteration)\n",
    "                            results.insert(0, iteration)\n",
    "        \n",
    "                            param_list.append(params)\n",
    "                            res_list.append(results)\n",
    "                \n",
    "                            print(f\"Iteration: {iteration}/{total_iteration_length}\")\n",
    "                \n",
    "                            iteration+=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "333d55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = pd.DataFrame(param_list, columns = [\"Train Index\", \"remove_stop_words\", \"remove_punctuations\", \"to_lower\", \"vocab_size\", \"embedding_dim\", \"sentence_length_threshold\", \"learning_rate\"])\n",
    "res_df = pd.DataFrame(res_list, columns = [\"Train Index\", \"train_accuracy\", \"test_accuracy\", \"train_loss\", \"test_loss\", \"f1\", \"auc_score\", \"training_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e66501ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Index</th>\n",
       "      <th>remove_stop_words</th>\n",
       "      <th>remove_punctuations</th>\n",
       "      <th>to_lower</th>\n",
       "      <th>vocab_size</th>\n",
       "      <th>embedding_dim</th>\n",
       "      <th>sentence_length_threshold</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>64</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>128</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Index  remove_stop_words  remove_punctuations  to_lower  vocab_size  \\\n",
       "0            1              False                False     False       10000   \n",
       "1            2              False                False     False       10000   \n",
       "2            3              False                False     False       10000   \n",
       "3            4              False                False     False       10000   \n",
       "4            5              False                False     False       10000   \n",
       "\n",
       "   embedding_dim  sentence_length_threshold  learning_rate  \n",
       "0             32                         29        0.00005  \n",
       "1             32                         29        0.00010  \n",
       "2             64                         29        0.00005  \n",
       "3             64                         29        0.00010  \n",
       "4            128                         29        0.00005  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06273664",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train Index</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>f1</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>training_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.883623</td>\n",
       "      <td>0.903288</td>\n",
       "      <td>0.223006</td>\n",
       "      <td>0.260273</td>\n",
       "      <td>0.865043</td>\n",
       "      <td>0.958661</td>\n",
       "      <td>38.417404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.938910</td>\n",
       "      <td>0.916828</td>\n",
       "      <td>0.119657</td>\n",
       "      <td>0.227933</td>\n",
       "      <td>0.885918</td>\n",
       "      <td>0.966860</td>\n",
       "      <td>24.450138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.968005</td>\n",
       "      <td>0.901032</td>\n",
       "      <td>0.227349</td>\n",
       "      <td>0.275904</td>\n",
       "      <td>0.867241</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>72.537886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.931899</td>\n",
       "      <td>0.894262</td>\n",
       "      <td>0.168820</td>\n",
       "      <td>0.280149</td>\n",
       "      <td>0.855837</td>\n",
       "      <td>0.955399</td>\n",
       "      <td>42.486187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.961557</td>\n",
       "      <td>0.916505</td>\n",
       "      <td>0.158633</td>\n",
       "      <td>0.210520</td>\n",
       "      <td>0.889721</td>\n",
       "      <td>0.972458</td>\n",
       "      <td>151.832433</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train Index  train_accuracy  test_accuracy  train_loss  test_loss  \\\n",
       "0            1        0.883623       0.903288    0.223006   0.260273   \n",
       "1            2        0.938910       0.916828    0.119657   0.227933   \n",
       "2            3        0.968005       0.901032    0.227349   0.275904   \n",
       "3            4        0.931899       0.894262    0.168820   0.280149   \n",
       "4            5        0.961557       0.916505    0.158633   0.210520   \n",
       "\n",
       "         f1  auc_score  training_time  \n",
       "0  0.865043   0.958661      38.417404  \n",
       "1  0.885918   0.966860      24.450138  \n",
       "2  0.867241   0.959361      72.537886  \n",
       "3  0.855837   0.955399      42.486187  \n",
       "4  0.889721   0.972458     151.832433  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b530a9bd",
   "metadata": {},
   "source": [
    "param_df.to_excel(\"cnn_param_df.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a9b1d425",
   "metadata": {},
   "source": [
    "res_df.to_excel(\"cnn_res_df.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92cfa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
